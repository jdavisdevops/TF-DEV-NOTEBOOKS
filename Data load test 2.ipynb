{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frozen-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x2a372654cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nvitop\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "# policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = pathlib.Path(\n",
    "    r\"C:\\Users\\jadav\\Desktop\\Tensorflow notebooks\\cats-v-dogs\\training\"\n",
    ")\n",
    "valdir = pathlib.Path(\n",
    "    r\"C:\\Users\\jadav\\Desktop\\Tensorflow notebooks\\cats-v-dogs\\testing\"\n",
    ")\n",
    "# import os\n",
    "\n",
    "# datadir = os.getcwd()\n",
    "# datadir = datadir + '/cats-v-dogs/testing/cats'\n",
    "# for fn in os.listdir(datadir):\n",
    "#     if fn[-3:-1] != 'jp':\n",
    "#         print(fn)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "logdir = pathlib.Path.cwd() / \"logs\"\n",
    "\n",
    "if logdir.exists():\n",
    "    !rmdir /q/s logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "# def check_images( s_dir, ext_list):\n",
    "#     bad_images=[]\n",
    "#     bad_ext=[]\n",
    "#     s_list= os.listdir(s_dir)\n",
    "#     for klass in s_list:\n",
    "#         klass_path=os.path.join (s_dir, klass)\n",
    "#         print ('processing class directory ', klass)\n",
    "#         if os.path.isdir(klass_path):\n",
    "#             file_list=os.listdir(klass_path)\n",
    "#             for f in file_list:\n",
    "#                 f_path=os.path.join (klass_path,f)\n",
    "#                 index=f.rfind('.')\n",
    "#                 ext=f[index+1:].lower()\n",
    "#                 if ext not in ext_list:\n",
    "#                     print('file ', f_path, ' has an invalid extension ', ext)\n",
    "#                     bad_ext.append(f_path)\n",
    "#                     os.remove(f_path)\n",
    "#                 if os.path.isfile(f_path):\n",
    "#                     try:\n",
    "#                         img=cv2.imread(f_path)\n",
    "#                         shape=img.shape\n",
    "#                     except:\n",
    "#                         print('file ', f_path, ' is not a valid image file')\n",
    "#                         bad_images.append(f_path)\n",
    "# #                         img = Image.open(f_path)\n",
    "# #                         img = img.save(f_path + \".jpeg\")\n",
    "#                         os.remove(f_path)\n",
    "#                 else:\n",
    "#                     print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
    "#         else:\n",
    "#             print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
    "#     return bad_images, bad_ext\n",
    "# ext_list = [\"jpg\"]\n",
    "# check_images(valdir, ext_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informal-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22289\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(datadir.glob(\"*/*.jpg\")))\n",
    "print(image_count)\n",
    "batch_size = 128\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amber-developer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-45eb3d41248c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_files = tf.data.Dataset.from_tensor_slices(list_ds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# val_files = tf.data.Dataset.from_tensor_slices(val_ds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_files' is not defined"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(datadir / \"*/*.jpg\"), shuffle=False)\n",
    "val_ds = tf.data.Dataset.list_files(str(valdir / \"*/*.jpg\"), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "# train_files = tf.data.Dataset.from_tensor_slices(list_ds)\n",
    "# val_files = tf.data.Dataset.from_tensor_slices(val_ds)\n",
    "# print(train_files, val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())\n",
    "print(\"validation\")\n",
    "for f in val_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(sorted([item.name for item in datadir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_size = int(image_count * .2)\n",
    "# train_ds = list_ds.skip(val_size)\n",
    "# val_ds = list_ds.take(val_size)\n",
    "train_ds = list_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == class_names\n",
    "    return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img  # tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image Shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        #         layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.01, interpolation=\"bilinear\"),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.01, interpolation=\"bilinear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "        layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    # Resize and rescale all datasets\n",
    "    ds = ds.map(lambda x, y: (resize_and_rescale(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    ds.cache()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Batch all datasets\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # Use data augmentation only on the training set\n",
    "    if augment:\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        )\n",
    "    #     if interleave:\n",
    "    #         ds = ds.interleave(list_ds.map(process_path, num_parallel_calls=AUTOTUNE), cycle_length=4, num_parallel_calls=AUTOTUNE)\n",
    "    # Use buffered prefecting on all datasets\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def configure_for_performance(ds):\n",
    "#     ds = ds.cache()\n",
    "#     ds = ds.shuffle(buffer_size=1000)\n",
    "#     ds = ds.batch(batch_size)\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "#     return ds\n",
    "# train_ds = configure_for_performance(train_ds)\n",
    "# val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(img_batch.numpy()[i])\n",
    "    label = label_batch[i]\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential(\n",
    "#     [\n",
    "#         tf.keras.layers.Conv2D(\n",
    "#             32, (3, 3), input_shape=(150, 150, 3), activation=\"relu\"\n",
    "#         ),\n",
    "#         tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#         tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(2, 2),\n",
    "# #         tf.keras.layers.Dropout(0.4),\n",
    "#         tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#         tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\"),\n",
    "#         #         tf.keras.layers.Maxpooling2D(2,2),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Dense(120, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(1, activation=\"relu\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        #         tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=\"500,520\"\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"auto\", patience=4, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# uploaded=files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "\n",
    "# predicting images\n",
    "#   path='/content/' + fn\n",
    "path = \"C:/Users/jadav/Desktop/Tensorflow notebooks/cat-dog-val/\"\n",
    "for fn in os.listdir(path):\n",
    "    img = image.load_img(path + fn, target_size=(150, 150))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    classes = model.predict(images, batch_size=32)\n",
    "\n",
    "    if classes[0] > 0:\n",
    "        print(fn + \" is a dog\")\n",
    "\n",
    "    else:\n",
    "        print(fn + \" is a cat\")\n",
    "# print(len(right_answers),len(wrong_answers), right_answers, wrong_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

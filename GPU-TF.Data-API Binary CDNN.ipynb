{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will install dependencies and display them in the notebook\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "# Install dependencies in Quiet Mode\n",
    "#!pip install -r -q requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complicated-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x206a6eac910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nvitop\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\" can slow down computation depending on setup and GPU type (developed on GTX 1660)\n",
    "tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "congressional-heater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mexican-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "datadir = pathlib.Path(\n",
    "    cwd / 'cats-v-dogs' /'training'\n",
    ")\n",
    "valdir = pathlib.Path(\n",
    "    cwd / 'cats-v-dogs' / 'testing'\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "logdir = pathlib.Path.cwd() / \"logs\"\n",
    "\n",
    "if logdir.exists():\n",
    "    !rmdir /q/s logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fatal-material",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22283\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(datadir.glob(\"*/*.jpg\")))\n",
    "print(image_count)\n",
    "batch_size = 128\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noted-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(datadir / \"*/*.jpg\"), shuffle=False)\n",
    "val_ds = tf.data.Dataset.list_files(str(valdir / \"*/*.jpg\"), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "num_train_files = len(list_ds)\n",
    "num_val_files = len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optical-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\dogs\\\\3294.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\cats\\\\534.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\cats\\\\2621.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\dogs\\\\3661.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\training\\\\dogs\\\\12031.jpg'\n",
      "validation\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\100.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10004.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10024.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10038.jpg'\n",
      "b'C:\\\\Users\\\\josephdavis\\\\Desktop\\\\Tensorflow notebooks\\\\cats-v-dogs\\\\testing\\\\cats\\\\10052.jpg'\n"
     ]
    }
   ],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())\n",
    "print(\"validation\")\n",
    "for f in val_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sophisticated-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats' 'dogs']\n"
     ]
    }
   ],
   "source": [
    "class_names = np.array(sorted([item.name for item in datadir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "swiss-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22283\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.cardinality(list_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emotional-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Process path functions for creating TF Data Pipeline\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == class_names\n",
    "    return tf.argmax(one_hot)\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spoken-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF.Data API using map, where the interleave seems to cause input data pipeline slowdown (I think it's my development CPU bottlenecking the multi-thread interleave process)\n",
    "\n",
    "train_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# train_ds = list_ds.interleave(\n",
    "#     lambda x: tf.data.Dataset.list_files(str(datadir / \"*/*.jpg\"), shuffle=True),\n",
    "#     num_parallel_calls=AUTOTUNE,\n",
    "#     cycle_length=4,\n",
    "# #     block_length=4,\n",
    "# #     deterministic=False,\n",
    "# ).map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.interleave(\n",
    "#     lambda x: tf.data.Dataset.list_files(str(valdir / \"*/*.jpg\"), shuffle=True),\n",
    "#     num_parallel_calls=AUTOTUNE,\n",
    "#     cycle_length=4,\n",
    "# #     block_length=4,\n",
    "# #     deterministic=False,\n",
    "# ).map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# train_ds.cache()\n",
    "# val_ds.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spatial-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation and resize/rescale preprocess layers\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        #         layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.01, interpolation=\"bilinear\"),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.01, interpolation=\"bilinear\"),\n",
    "#         layers.experimental.preprocessing.RandomContrast(0.2), re-enable these if over-fitting on data\n",
    "#         layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "        layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hundred-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ds, shuffle=False, augment=False):\n",
    "\n",
    "    # Resize and rescale all datasets.\n",
    "    ds = ds.map(lambda x, y: (resize_and_rescale(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # cache all datasets after resize/rescale\n",
    "    ds.cache()\n",
    "\n",
    "    # shuffle only Training DS\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Batch all datasets\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # augment only training dataset, call cache after augmentation dramatically increases input speed\n",
    "    if augment:\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        ).cache()\n",
    "\n",
    "    # Use buffered prefecting on all datasets\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "\n",
    "#experimental options for increasing input data pipeline speed further \n",
    "# options = tf.data.Options()\n",
    "# options.experimental_threading.max_intra_op_parallelism = 1\n",
    "# train_ds = train_ds.with_options(options)\n",
    "# val_ds = val_ds.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inside-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dropout(.2), if need due to overfit\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# resnet_model = tf.keras.applications.ResNet50(\n",
    "# include_top=False, weights='imagenet',input_shape=(224,224,3), pooling ='avg')\n",
    "# for layer in resnet_model.layers:\n",
    "#     layer.trainable = False\n",
    "# resnet_model.add(tf.keras.layers.Flatten())\n",
    "# output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "# # resnet_model.add(output_layer_)\n",
    "# model = tf.keras.models.Model(inputs=resnet_model.input, outputs = output_layer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "engaged-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create LogDir for Tensorboard writing\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=\"500,520\"\n",
    ")\n",
    "\n",
    "#early stopping callback for when val_loss drops more than 3 epochs in a row, restores best weights from model training\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"auto\", patience=3, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "marine-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 54s 274ms/step - loss: 0.8589 - accuracy: 0.5456 - val_loss: 0.6024 - val_accuracy: 0.6886\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 26s 150ms/step - loss: 0.6168 - accuracy: 0.6611 - val_loss: 0.5340 - val_accuracy: 0.7319\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 27s 152ms/step - loss: 0.5717 - accuracy: 0.7027 - val_loss: 0.5104 - val_accuracy: 0.7634\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 25s 144ms/step - loss: 0.5325 - accuracy: 0.7302 - val_loss: 0.5470 - val_accuracy: 0.7388\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 25s 144ms/step - loss: 0.4941 - accuracy: 0.7574 - val_loss: 0.5109 - val_accuracy: 0.7679\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 26s 151ms/step - loss: 0.4519 - accuracy: 0.7851 - val_loss: 0.5313 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tboard_callback],\n",
    "    # enable steps per epoch and val steps if using tf.data.interleave(map_func, num_parallel_calls).map(process_path)\n",
    "    #     steps_per_epoch=int(num_train_files / batch_size),\n",
    "    #     validation_steps=int(num_val_files / batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "german-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 58252), started 7 days, 5:46:20 ago. (Use '!kill 58252' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-75d535390da79204\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-75d535390da79204\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#notebook magic for t-board extension loading and calling in-line tboard from logdir\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "upset-interface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 75ms/step - loss: 0.5104 - accuracy: 0.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5104008316993713, 0.7634451985359192]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncomment for evaluation on validation dataset\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "apparent-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4387]\n",
      "127.jpg is a dog\n",
      "[0.6865]\n",
      "137.jpg is a dog\n",
      "[0.7637]\n",
      "140.jpg is a dog\n",
      "[0.446]\n",
      "159.jpg is a dog\n",
      "[0.998]\n",
      "196.jpg is a dog\n",
      "[0.1104]\n",
      "205.jpg is a dog\n",
      "[0.6865]\n",
      "218.jpg is a dog\n",
      "[0.982]\n",
      "220.jpg is a dog\n",
      "[0.7666]\n",
      "222.jpg is a dog\n",
      "[0.9688]\n",
      "229.jpg is a dog\n",
      "[0.524]\n",
      "232.jpg is a dog\n",
      "[0.9863]\n",
      "243.jpg is a dog\n",
      "[0.146]\n",
      "274.jpg is a dog\n",
      "[0.8784]\n",
      "279.jpg is a dog\n",
      "[0.648]\n",
      "285.jpg is a dog\n",
      "[0.999]\n",
      "321.jpg is a dog\n",
      "[0.417]\n",
      "326.jpg is a dog\n",
      "[0.2354]\n",
      "330.jpg is a dog\n",
      "[0.982]\n",
      "338.jpg is a dog\n",
      "[0.0642]\n",
      "345.jpg is a dog\n",
      "[0.87]\n",
      "346.jpg is a dog\n",
      "[0.905]\n",
      "353.jpg is a dog\n",
      "[0.2126]\n",
      "363.jpg is a dog\n",
      "[0.634]\n",
      "365.jpg is a dog\n",
      "[0.907]\n",
      "402.jpg is a dog\n",
      "[0.909]\n",
      "407.jpg is a dog\n",
      "[0.768]\n",
      "409.jpg is a dog\n",
      "[0.9395]\n",
      "425.jpg is a dog\n",
      "[0.6294]\n",
      "427.jpg is a dog\n",
      "[0.998]\n",
      "437.jpg is a dog\n",
      "[0.7896]\n",
      "455.jpg is a dog\n",
      "[0.8354]\n",
      "463.jpg is a dog\n",
      "[0.3833]\n",
      "471.jpg is a dog\n",
      "[0.4922]\n",
      "483.jpg is a dog\n",
      "[0.984]\n",
      "487.jpg is a dog\n",
      "[0.6143]\n",
      "517.jpg is a dog\n",
      "[0.804]\n",
      "519.jpg is a dog\n",
      "[0.2]\n",
      "533.jpg is a dog\n",
      "[0.9854]\n",
      "546.jpg is a dog\n",
      "[0.8853]\n",
      "5577.jpg is a dog\n",
      "[0.2009]\n",
      "5589.jpg is a dog\n",
      "[0.6016]\n",
      "559.jpg is a dog\n",
      "[0.993]\n",
      "5609.jpg is a dog\n",
      "[0.3582]\n",
      "5625.jpg is a dog\n",
      "[0.712]\n",
      "5629.jpg is a dog\n",
      "[0.2134]\n",
      "5641.jpg is a dog\n",
      "[0.0901]\n",
      "5644.jpg is a dog\n",
      "[0.4338]\n",
      "5651.jpg is a dog\n",
      "[0.2072]\n",
      "5653.jpg is a dog\n",
      "[0.2306]\n",
      "5662.jpg is a dog\n",
      "[0.05368]\n",
      "5668.jpg is a dog\n",
      "[0.612]\n",
      "5671.jpg is a dog\n",
      "[0.35]\n",
      "5681.jpg is a dog\n",
      "[0.1843]\n",
      "5704.jpg is a dog\n",
      "[0.0643]\n",
      "5705.jpg is a dog\n",
      "[0.03992]\n",
      "5719.jpg is a dog\n",
      "[0.3767]\n",
      "5724.jpg is a dog\n",
      "[0.008095]\n",
      "5725.jpg is a dog\n",
      "[0.1031]\n",
      "5758.jpg is a dog\n",
      "[0.9697]\n",
      "576.jpg is a dog\n",
      "[0.127]\n",
      "5762.jpg is a dog\n",
      "[0.0451]\n",
      "5766.jpg is a dog\n",
      "[0.4124]\n",
      "5768.jpg is a dog\n",
      "[0.585]\n",
      "5769.jpg is a dog\n",
      "[0.2471]\n",
      "5773.jpg is a dog\n",
      "[0.0461]\n",
      "5774.jpg is a dog\n",
      "[0.999]\n",
      "578.jpg is a dog\n",
      "[0.11816]\n",
      "579.jpg is a dog\n",
      "[0.4216]\n",
      "5793.jpg is a dog\n",
      "[0.8613]\n",
      "5795.jpg is a dog\n",
      "[0.86]\n",
      "580.jpg is a dog\n",
      "[0.742]\n",
      "5805.jpg is a dog\n",
      "[0.09796]\n",
      "5830.jpg is a dog\n",
      "[0.4587]\n",
      "5847.jpg is a dog\n",
      "[0.6284]\n",
      "5851.jpg is a dog\n",
      "[0.08344]\n",
      "5854.jpg is a dog\n",
      "[0.2827]\n",
      "5866.jpg is a dog\n",
      "[0.519]\n",
      "5874.jpg is a dog\n",
      "[0.7817]\n",
      "5877.jpg is a dog\n",
      "[0.06082]\n",
      "5883.jpg is a dog\n",
      "[0.163]\n",
      "5890.jpg is a dog\n",
      "[0.00624]\n",
      "5898.jpg is a dog\n",
      "[0.0542]\n",
      "5907.jpg is a dog\n",
      "[0.2812]\n",
      "5911.jpg is a dog\n",
      "[0.0494]\n",
      "5935.jpg is a dog\n",
      "[0.0764]\n",
      "5946.jpg is a dog\n",
      "[0.257]\n",
      "5957.jpg is a dog\n",
      "[0.525]\n",
      "6034.jpg is a dog\n",
      "[0.1736]\n",
      "6041.jpg is a dog\n",
      "[0.549]\n",
      "6054.jpg is a dog\n",
      "[0.2056]\n",
      "6063.jpg is a dog\n",
      "[0.0922]\n",
      "6074.jpg is a dog\n",
      "[0.0801]\n",
      "6076.jpg is a dog\n",
      "[0.1388]\n",
      "6080.jpg is a dog\n",
      "[0.591]\n",
      "613.jpg is a dog\n",
      "[0.4482]\n",
      "620.jpg is a dog\n",
      "[0.6343]\n",
      "626.jpg is a dog\n",
      "[0.834]\n",
      "637.jpg is a dog\n",
      "[0.6963]\n",
      "648.jpg is a dog\n",
      "[0.855]\n",
      "666.jpg is a dog\n",
      "[0.404]\n",
      "671.jpg is a dog\n",
      "[0.2123]\n",
      "681.jpg is a dog\n",
      "[0.2273]\n",
      "693.jpg is a dog\n",
      "[0.914]\n",
      "702.jpg is a dog\n",
      "[0.9175]\n",
      "723.jpg is a dog\n",
      "[0.007603]\n",
      "726.jpg is a dog\n",
      "[0.9883]\n",
      "735.jpg is a dog\n",
      "[0.0571]\n",
      "737.jpg is a dog\n",
      "[0.915]\n",
      "747.jpg is a dog\n",
      "[0.9185]\n",
      "753.jpg is a dog\n",
      "[0.88]\n",
      "766.jpg is a dog\n",
      "[0.9893]\n",
      "783.jpg is a dog\n",
      "[1.]\n",
      "811.jpg is a dog\n",
      "[0.801]\n",
      "813.jpg is a dog\n",
      "[0.9087]\n",
      "814.jpg is a dog\n",
      "[0.4453]\n",
      "822.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# uploaded=files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "\n",
    "# predicting images\n",
    "#   path='/content/' + fn\n",
    "path = \"C:/Users/josephdavis/Desktop/Tensorflow notebooks/cat-dog-val/\"\n",
    "for fn in os.listdir(path):\n",
    "    img = image.load_img(path + fn, target_size=(150, 150))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = x/255.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    \n",
    "\n",
    "    if classes[0] > 0:\n",
    "        print(classes[0])\n",
    "        print(fn + \" is a dog\")\n",
    "\n",
    "    else:\n",
    "        print(fn + \" is a cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
